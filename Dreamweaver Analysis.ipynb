{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Dreamweaver AI**\n",
        "The goal of this project is to create the use of LLM for coherent story generation.\n",
        "\n",
        "The plan is to use a base model to tune it to the use case. However, we did not have enough time and resources for training, therefore, we did just simple analysis on our rugged approach."
      ],
      "metadata": {
        "id": "gWE3tvYahdzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "Nothing fancy here, just your typical imports, and prerequisites."
      ],
      "metadata": {
        "id": "w_sZQoDjkihI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install OpenAI tiktoken\n",
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yElQUF0wi6vD",
        "outputId": "cd108dc6-90e8-41e5-8d9c-e0b76afb690b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: OpenAI in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from OpenAI) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (4.12.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->OpenAI) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->OpenAI) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->OpenAI) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->OpenAI) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->OpenAI) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->OpenAI) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->OpenAI) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Collecting en-core-web-md==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "from typing import List, Dict, Optional #Conradium\n",
        "import tiktoken\n",
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "import spacy\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyYnrZ6bke19",
        "outputId": "ddbe9e0b-0f55-4744-d9f7-c96e20532008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "yw3_1NS2kuJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classes\n",
        "Collection of classes, for story generation and evaluation"
      ],
      "metadata": {
        "id": "u3B2slzlknDh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Story Generator\n",
        "Here I use OpenAI API for the model mistral 7b instruct.\n",
        "Instead of hosting a model from hugging face straight in colab, I used a readily available base model.\n",
        "\n",
        "Their API is free to use."
      ],
      "metadata": {
        "id": "egmSVjfLlUj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StoryGenerator:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: str = \"mistralai/mistral-7b-instruct:free\",\n",
        "        max_tokens: int = 4000,\n",
        "        iterations: int = 2,\n",
        "        temperature: float = 0.7,\n",
        "        top_p: float = 0.9\n",
        "    ):\n",
        "\n",
        "        # API\n",
        "        self.client = OpenAI(\n",
        "            base_url='https://openrouter.ai/api/v1',\n",
        "            api_key=userdata.get('openSecret')\n",
        "        )\n",
        "\n",
        "        self.model = model\n",
        "        self.max_tokens = max_tokens\n",
        "        self.iterations = iterations\n",
        "        self.temperature = temperature\n",
        "        self.top_p = top_p\n",
        "        self.tokenizer = tiktoken.get_encoding(\"cl100k_base\") #Conradium\n",
        "        self.story_memory: List[Dict] = []\n",
        "\n",
        "    def _generate_completion(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        system_message: Optional[str] = None\n",
        "    ) -> str:\n",
        "        \"\"\"Generate text completion with error handling\"\"\"\n",
        "        try:\n",
        "            messages = []\n",
        "\n",
        "            if system_message:\n",
        "                messages.append({\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": system_message\n",
        "                })\n",
        "\n",
        "            messages.append({\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            })\n",
        "\n",
        "            completion = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=messages,\n",
        "                max_tokens=self.max_tokens,\n",
        "                temperature=self.temperature,\n",
        "                top_p=self.top_p\n",
        "            )\n",
        "\n",
        "            generated_text = completion.choices[0].message.content\n",
        "\n",
        "            # Update story memory\n",
        "            self.story_memory.append({\n",
        "                \"prompt\": prompt,\n",
        "                \"response\": generated_text\n",
        "            })\n",
        "\n",
        "            return generated_text\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating completion: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def generate_story(\n",
        "        self,\n",
        "        initial_prompt: str,\n",
        "        system_prompt: Optional[str] = None\n",
        "    ) -> str:\n",
        "        if not system_prompt:\n",
        "            system_prompt = (\n",
        "                \"You are a consistent storyteller. \"\n",
        "                \"Maintain narrative flow, character development, \"\n",
        "                \"and thematic coherence throughout the story.\"\n",
        "            )\n",
        "\n",
        "        full_text = self._generate_completion(\n",
        "            initial_prompt,\n",
        "            system_message=system_prompt\n",
        "        )\n",
        "\n",
        "        # Iterative story expansion\n",
        "        for _ in range(self.iterations - 1):\n",
        "            # context management: Use last 2000 tokens\n",
        "            tokens = self.tokenizer.encode(full_text)\n",
        "            context_tokens = tokens[-2000:]\n",
        "            context = self.tokenizer.decode(context_tokens)\n",
        "\n",
        "            continuation_prompt = (\n",
        "                f\"Continue the narrative, maintaining tone and style. \"\n",
        "                f\"Previous Context:\\n{context}\\n\\n\"\n",
        "                \"Seamlessly extend the story, ensuring narrative coherence.\"\n",
        "            )\n",
        "\n",
        "            continuation = self._generate_completion(\n",
        "                continuation_prompt,\n",
        "                system_message=system_prompt\n",
        "            )\n",
        "\n",
        "            full_text += \"\\n\\n\" + continuation\n",
        "\n",
        "        return full_text\n",
        "\n",
        "    def analyze_story_structure(self, story: str) -> Dict:\n",
        "        analysis_prompt = (\n",
        "            f\"Analyze the narrative structure of the following story:\\n\\n{story}\\n\\n\"\n",
        "            \"Provide insights on: plot progression, character arcs, \"\n",
        "            \"themes, and potential narrative turning points.\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"raw_analysis\": self._generate_completion(analysis_prompt)\n",
        "        }\n",
        "\n",
        "\n",
        "#Conradium\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tIbyX2fhhm1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I put in an unused function, analyze story structure and progression. This is for a deeper understanding how deep does the AI model understand the story.\n",
        "\n",
        "Sometimes, what we see in the analysis is different than the generated text. We often see greater depth in the analysis than the generated text.\n",
        "\n",
        "The reason behind might be do to the lack of reasoning when generation."
      ],
      "metadata": {
        "id": "EL3oytPmpnKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Story Coherence Evaluator"
      ],
      "metadata": {
        "id": "pmmH4Kc7lQU-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Honestly, half of these concepts understanding are found on the internet.\n",
        "It consists of natural language toolkit (nltk), BLEU and spaCy.\n",
        "Basically what it does are:\n",
        "\n",
        "NLTK:\n",
        "1. Tokenization: Break down words or sentences\n",
        "2. Stemming and lemmatization: Reduce words to their base root form\n",
        "3. Text classification\n",
        "\n",
        "Bleu (Bilingual Evaluation Understudy)'s role:\n",
        "1. N-gram matching: Considers matches of different lengths, 1,2,3 grams etc to capture similarities level.\n",
        "\n",
        "SpaCy:\n",
        "1. Tokenization\n",
        "2. Part-of-speech tagging: Identifying grammatical category\n",
        "3. Named entity recognition: Identifying and classifying named entities in the text like organizations and people\n",
        "4. Dependency parsing: Analyuze grammatical structure of a sentence.\n",
        "5. Word embeddings: Representing words as vectors in a high-dimensional space, which helps in capturing semantic meaning."
      ],
      "metadata": {
        "id": "tsXEtp0gqLwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StoryCoherenceEvaluator:\n",
        "    def __init__(self):\n",
        "        try:\n",
        "            self.nlp = spacy.load('en_core_web_md')\n",
        "            nltk.download('punkt')\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading NLP models: {e}\")\n",
        "            raise\n",
        "\n",
        "    def semantic_coherence(self, text):\n",
        "        doc = self.nlp(text)\n",
        "        doc_vector = np.mean([token.vector for token in doc if token.has_vector], axis=0)\n",
        "\n",
        "        sentences = [sent.text for sent in doc.sents]\n",
        "        sentence_vectors = [self.nlp(sent).vector for sent in sentences]\n",
        "\n",
        "        similarities = []\n",
        "        for i in range(1, len(sentence_vectors)):\n",
        "            similarity = cosine_similarity(\n",
        "                sentence_vectors[i-1].reshape(1, -1),\n",
        "                sentence_vectors[i].reshape(1, -1)\n",
        "            )[0][0]\n",
        "            similarities.append(similarity)\n",
        "\n",
        "        return {\n",
        "            'avg_sentence_similarity': np.mean(similarities) if similarities else 0,\n",
        "            'semantic_coherence_score': np.mean(similarities) if similarities else 0\n",
        "        }\n",
        "\n",
        "    def lexical_coherence(self, text):\n",
        "        sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "        # TF-IDF vectorization\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        tfidf_matrix = vectorizer.fit_transform(sentences)\n",
        "\n",
        "        # Compute cosine similarities between consecutive sentences #THANK YOU CLAUDE SONNET\n",
        "        similarities = []\n",
        "        for i in range(1, len(sentences)):\n",
        "            similarity = cosine_similarity(\n",
        "                tfidf_matrix[i-1],\n",
        "                tfidf_matrix[i]\n",
        "            )[0][0]\n",
        "            similarities.append(similarity)\n",
        "\n",
        "        return {\n",
        "            'lexical_similarity': np.mean(similarities) if similarities else 0,\n",
        "            'lexical_coherence_score': np.mean(similarities) if similarities else 0\n",
        "        }\n",
        "\n",
        "    def narrative_flow_evaluation(self, text):\n",
        "        sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "        # finds candidates for similarity/pattern in the output\n",
        "        bleu_scores = []\n",
        "        for i in range(1, len(sentences)):\n",
        "            reference = [sentences[i-1].split()]\n",
        "            candidate = sentences[i].split()\n",
        "            bleu_score = sentence_bleu(reference, candidate)\n",
        "            bleu_scores.append(bleu_score)\n",
        "\n",
        "        return {\n",
        "            'narrative_flow_score': np.mean(bleu_scores) if bleu_scores else 0,\n",
        "            'narrative_progression_variance': np.std(bleu_scores) if bleu_scores else 0\n",
        "        }\n",
        "\n",
        "    def comprehensive_coherence_analysis(self, text):\n",
        "        semantic_analysis = self.semantic_coherence(text)\n",
        "        lexical_analysis = self.lexical_coherence(text)\n",
        "        narrative_analysis = self.narrative_flow_evaluation(text)\n",
        "\n",
        "        # scores combined with weight (reason: adjustable preference)\n",
        "        coherence_score = (\n",
        "            0.4 * semantic_analysis['semantic_coherence_score'] +\n",
        "            0.3 * lexical_analysis['lexical_coherence_score'] +\n",
        "            0.3 * narrative_analysis['narrative_flow_score']\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'overall_coherence_score': coherence_score,\n",
        "            'semantic_coherence': semantic_analysis,\n",
        "            'lexical_coherence': lexical_analysis,\n",
        "            'narrative_flow': narrative_analysis\n",
        "        }"
      ],
      "metadata": {
        "id": "6VDhlzcxk0I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I also weighed the coherence score in this way\n",
        "\n",
        "semantic:lexical:narrative\n",
        "\n",
        "4:3:3"
      ],
      "metadata": {
        "id": "v3XGmDXDr_bJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Usage"
      ],
      "metadata": {
        "id": "S5u0bVCjlyGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Story"
      ],
      "metadata": {
        "id": "mCk3Ym69mWiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "story_generator = StoryGenerator()\n",
        "initial_prompt = (\n",
        "    \"In a world where time flows differently in certain geographical regions, \"\n",
        "    \"tell the story of a young cartographer who inherits a device capable of \"\n",
        "    \"synchronizing time across these disparate zones.\"\n",
        ")\n",
        "\n",
        "story = story_generator.generate_story(initial_prompt)\n",
        "print(\"Generated Story:\\n\" + \"\\n\".join(line.strip() for line in story.split(\"\\n\") if line.strip()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibzgufCSl3Nz",
        "outputId": "31cfeabe-8819-47b0-c09b-583bbdd0d156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Story:\n",
            "Title: The Chronomap: A Tale of Time and Tides\n",
            "In the quaint, cobblestone streets of the ancient city of Chronopolis, a young cartographer named Aria lived. Born to a family of scholars and navigators, Aria had spent her life mapping the intricate labyrinth of streets, studying the arcane tomes of her ancestors, and learning the secrets of the city's unique chronodynamic properties.\n",
            "Chronopolis was a city unlike any other. Its location lay at the intersection of five time zones, each with its own rhythm and flow. The city's clocks ran at different speeds, and the streets were a symphony of ticking and tocking, the sounds harmonizing in a cacophony that was both enchanting and disconcerting.\n",
            "Aria's father, a renowned scholar and inventor, had spent his life studying these time zones and their impact on the city's inhabitants. He had devoted his final years to the creation of a device that could synchronize the city's clocks, bringing harmony to the chaos and ensuring that the citizens of Chronopolis could live in a world where time flowed evenly.\n",
            "Tragically, Aria's father passed away before he could complete his life's work. The device, a complex and beautiful contraption known as the Chronomap, was left to Aria. With a heavy heart, she vowed to complete her father's work and bring unity to Chronopolis.\n",
            "Aria spent countless hours studying her father's notes, deciphering the intricate ciphers and diagrams that made up the Chronomap's blueprints. She worked tirelessly, driven by her love for her father and her desire to bring harmony to her city.\n",
            "As she delved deeper into her father's work, Aria began to uncover the hidden depths of the Chronomap. She discovered that the device was not just a tool for synchronizing clocks; it was a key to understanding the very fabric of time itself.\n",
            "The Chronomap was a marvel of engineering and magic, a testament to her father's genius. It was a complex network of gears, levers, and enchanted crystals, each piece carefully crafted to work in harmony with the others. It was a puzzle, a mystery, and a challenge that Aria was determined to solve.\n",
            "As she worked, Aria began to notice changes in the city. The streets seemed to flow more smoothly, the clocks ticked in unison, and the people of Chronopolis seemed happier and more harmonious. The city was changing, and Aria knew that the Chronomap was the cause.\n",
            "However, as the device neared completion, Aria began to experience strange visions. She saw glimpses of a world where time flowed evenly, where the five time zones were no more, and where people lived in harmony with the rhythm of the universe. She saw a world that her father had dreamed of, a world that she could help create.\n",
            "But with this vision came a terrible price. Aria began to age rapidly, the passage of time accelerating within her. She knew that if she continued to work on the Chronomap, she would soon wither away, her life cut short by the very device she sought to create.\n",
            "Faced with this impossible choice, Aria made a decision. She would complete the Chronomap, but not for herself. She would give the device to the people of Chronopolis, allowing them to decide its fate.\n",
            "With a heavy heart, Aria finished the Chronomap. She gathered the citizens of Chronopolis in the city square, presenting them with the device that could change their world forever. She told them of her father's vision, of the harmony that could be achieved if they embraced the unity of time.\n",
            "The people of Chronopolis were divided. Some saw the benefits of a world where time flowed evenly, where the chaos of the city's clocks was no more. Others feared the unknown, the potential consequences of tampering with the very fabric of time.\n",
            "In the end, it was the city's elders who made the decision. They saw the potential for harmony, for a brighter future for their people. They agreed to activate the Chronomap, to bring unity to Chronopolis.\n",
            "As the device was activated, the city trembled. The clocks began to synchronize, their ticking and tocking harmonizing into a single, rhythmic beat. The streets flowed more smoothly, the people moved with a newfound sense of purpose, and the air seemed to crackle with energy.\n",
            "But as the last clock chimed\n",
            "In the moments following the activation of the Chronomap, Aria watched as Chronopolis transformed before her eyes. The streets glowed with a soft, ethereal light, the air crackled with energy, and the people moved with a newfound sense of purpose. The city seemed to breathe, its very essence aligning with the rhythm of the universe.\n",
            "Aria, her heart swelling with pride and sadness, knew that her time had come. She had completed her father's work, but at a terrible cost. She felt her body begin to wither, the passage of time accelerating within her. She knew that she would not see the full impact of her actions, that she would not witness the true harmony her father had dreamed of.\n",
            "With a final, tearful glance at the city she loved, Aria closed her eyes and let the embrace of the Chronomap take her. She felt herself slipping away, her consciousness fading as the last remnants of her life drained away.\n",
            "But as she slipped into the darkness, Aria felt a sense of peace wash over her. She knew that she had accomplished her mission, that she had brought harmony to Chronopolis. She knew that her father's dream would live on, carried forward by the people she loved.\n",
            "And as her life faded away, Aria felt a hand on her shoulder. She opened her eyes to see her father, his face filled with love and pride. He told her that he was proud of her, that she had done well. He told her that her sacrifice would not be in vain, that the people of Chronopolis would remember her name.\n",
            "With a final smile, Aria closed her eyes for the last time. The people of Chronopolis mourned their lost hero, but they also celebrated the new world they had been given. They knew that Aria's sacrifice had been worth it, that the harmony she had brought to their city would last for generations to come.\n",
            "And so, Chronopolis thrived, a beacon of unity in a world of chaos. The city's clocks continued to tick in unison, the streets flowing smoothly, and the people moving with a newfound sense of purpose. Aria's name became a legend, a story passed down from generation to generation, a testament to the power of love, sacrifice, and the harmony of time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Coherence Evaluation"
      ],
      "metadata": {
        "id": "2N1dm-7SmYvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coherence_evaluator = StoryCoherenceEvaluator()\n",
        "coherence_analysis = coherence_evaluator.comprehensive_coherence_analysis(story)\n",
        "\n",
        "print(\"Coherence Analysis:\")\n",
        "\n",
        "overall_coherence_df = pd.DataFrame({\n",
        "    'overall_coherence_score': [coherence_analysis['overall_coherence_score']]\n",
        "})\n",
        "\n",
        "\n",
        "semantic_coherence_df = pd.DataFrame.from_dict(coherence_analysis['semantic_coherence'], orient='index').T\n",
        "lexical_coherence_df = pd.DataFrame.from_dict(coherence_analysis['lexical_coherence'], orient='index').T\n",
        "narrative_flow_df = pd.DataFrame.from_dict(coherence_analysis['narrative_flow'], orient='index').T\n",
        "\n",
        "print(\"Overall Coherence Score:\\n\" + overall_coherence_df.to_markdown(index=False))\n",
        "print(\"\\nSemantic Coherence:\\n\" + semantic_coherence_df.to_markdown(index=False))\n",
        "print(\"\\nLexical Coherence:\\n\" + lexical_coherence_df.to_markdown(index=False))\n",
        "print(\"\\nNarrative Flow:\\n\" + narrative_flow_df.to_markdown(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mvtld5Zhk16z",
        "outputId": "ca07d1b7-83a1-42a7-f4d4-93a52f01fae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence Analysis:\n",
            "Overall Coherence Score:\n",
            "|   overall_coherence_score |\n",
            "|--------------------------:|\n",
            "|                  0.364913 |\n",
            "\n",
            "Semantic Coherence:\n",
            "|   avg_sentence_similarity |   semantic_coherence_score |\n",
            "|--------------------------:|---------------------------:|\n",
            "|                   0.83585 |                    0.83585 |\n",
            "\n",
            "Lexical Coherence:\n",
            "|   lexical_similarity |   lexical_coherence_score |\n",
            "|---------------------:|--------------------------:|\n",
            "|            0.0997712 |                 0.0997712 |\n",
            "\n",
            "Narrative Flow:\n",
            "|   narrative_flow_score |   narrative_progression_variance |\n",
            "|-----------------------:|---------------------------------:|\n",
            "|             0.00213948 |                        0.0167099 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}